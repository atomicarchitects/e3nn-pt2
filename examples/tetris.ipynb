{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tinygrad import Tensor, dtypes\n",
    "\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Disable future warnings.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import Device\n",
    "Device.DEFAULT = \"GPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for left and right screws.\n",
    "tetracubes = np.array([\n",
    "  # Right screw.\n",
    "  [ [ -0.50,  0.25, -0.25 ], [ -0.50,  0.25,  0.75 ],\n",
    "    [  0.50,  0.25, -0.25 ], [  0.50, -0.75, -0.25 ] ],\n",
    "  # Left screw.\n",
    "  [ [ -0.75,  0.50, -0.25 ], [  0.25, -0.50,  0.75 ],\n",
    "    [  0.25,  0.50, -0.25 ], [  0.25, -0.50, -0.25 ] ],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets(num_train=1000, num_valid=100, noise_scale=0.05):\n",
    "\n",
    "  # Assign a label to each tetracube.\n",
    "  labels = np.arange(tetracubes.shape[0])\n",
    "\n",
    "  # Randomly choose among the eight tetracubes to generate train and validation datasets.\n",
    "  train_choice = np.random.choice(tetracubes.shape[0], size=(num_train,))\n",
    "  valid_choice = np.random.choice(tetracubes.shape[0], size=(num_valid,))\n",
    "  train_shapes = Tensor(np.take(tetracubes, train_choice, axis=0), dtype=dtypes.default_float, requires_grad=True)\n",
    "  valid_shapes = Tensor(np.take(tetracubes, valid_choice, axis=0), dtype=dtypes.default_float, requires_grad=True)\n",
    "  train_labels = Tensor(np.take(labels, train_choice, axis=0), dtype=dtypes.default_float, requires_grad=True)\n",
    "  valid_labels = Tensor(np.take(labels, valid_choice, axis=0), dtype=dtypes.default_float, requires_grad=True)\n",
    "  \n",
    "  # Add Gaussian noise for some variety.\n",
    "  train_shapes = train_shapes + noise_scale * Tensor(np.random.normal(size=train_shapes.shape), dtype=dtypes.default_float)\n",
    "  valid_shapes = valid_shapes + noise_scale * Tensor(np.random.normal(size=valid_shapes.shape), dtype=dtypes.default_float)\n",
    "  \n",
    "  # Return final train and validation datasets.\n",
    "  train_data = dict(shapes=train_shapes.realize(), labels=train_labels.realize())\n",
    "  valid_data = dict(shapes=valid_shapes.realize(), labels=valid_labels.realize())\n",
    "  return train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Protocol, Tuple, Union, List\n",
    "from tinygrad import Tensor\n",
    "\n",
    "def basis(\n",
    "    r: Tensor,\n",
    "    max_degree: int,\n",
    "    num: int,\n",
    "    # radial_fn: Callable[[Float[Array, '...'], int], Float[Array, '... num']],\n",
    "):\n",
    "    r\"\"\"Basis function corresponding to e3x.nn.basis which uses\n",
    "        e3nn.spherical_harmonics for angular functions\n",
    "    \"\"\"\n",
    "    \n",
    "    original_shape = r.shape[:-1]\n",
    "    r = r.reshape(-1, 3)\n",
    "\n",
    "    # Normalize input vectors.\n",
    "    a = torch.maximum(torch.max(torch.abs(r)), torch.finfo(r.dtype).tiny)\n",
    "    b = r / a\n",
    "    norm = a * torch.sqrt(torch.sum(b * b, dim=-1, keepdim=True))\n",
    "    u = r / torch.where(norm > 0, norm, 1)\n",
    "    norm = norm.squeeze(-1)  # (...)\n",
    "\n",
    "    # radial function\n",
    "    # rbf = radial_fn(norm, num)  # (..., N)\n",
    "\n",
    "    # basis function\n",
    "    ylm = e3nn.spherical_harmonics(e3nn.s2_irreps(max_degree), u, normalize=\"component\")\n",
    "    return ylm\n",
    "    \n",
    "    product = lambda x, weight: lambda w: w * x(weight)(ylm, rbf)\n",
    "\n",
    "    return product.reshape((*original_shape, *product.shape[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2235380749.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[123], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    tp =\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class TensorDense(torch.nn.Module):\n",
    "\n",
    "    features: int\n",
    "    max_degree: int\n",
    "    irreps_out: e3nn.Irreps\n",
    "    use_gaunt: bool\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: e3nn.IrrepsArray) -> e3nn.IrrepsArray:\n",
    "\n",
    "        x1 = e3nn.o3.Linear(irreps_in=x.irreps, irreps_out=x.irreps, channel_out=self.features)(x)\n",
    "        x2 = e3nn.o3.Linear(irreps_in=x.irreps, irreps_out=x.irreps, channel_out=self.features)(x)\n",
    "            \n",
    "        # Keep irreps only up to max_degree.\n",
    "        filter_ir_out = e3nn.tensor_product(x1.irreps, x2.irreps).filter(\n",
    "            lmax=self.max_degree\n",
    "        )\n",
    "    \n",
    "        tp = \n",
    "\n",
    "        # Additionally, filter out irreps.\n",
    "        irreps_out = self.irreps_out\n",
    "        if irreps_out is None:\n",
    "            irreps_out = tp.irreps\n",
    "\n",
    "        x = e3nn.o3.Linear(irreps_in=tp.irreps_out, irreps_out=irreps_out)(tp)        \n",
    "        return x\n",
    "\n",
    "class E3NNModel(torch.nn.Module):\n",
    "  features = 8\n",
    "  max_degree = 3\n",
    "  use_gaunt: bool = False\n",
    "\n",
    "  def __call__(self, shapes):  # The 'shapes' array has shape (..., 4, 3).\n",
    "      \n",
    "    # 1. Center shapes at origin (for translational invariance).\n",
    "    shapes -= torch.mean(shapes, keepdims=True, axis=-2)   # 'shapes' still has shape (..., 4, 3).\n",
    "    \n",
    "    # 2. Featurize by expanding cube midpoints in basis functions and taking the mean over the 4 cubes.\n",
    "    \n",
    "    x = basis( \n",
    "      shapes,\n",
    "      num=self.features,\n",
    "      max_degree=self.max_degree,\n",
    "    #   radial_fn=functools.partial(e3x.nn.triangular_window, limit=2.0),\n",
    "    ) # 'x' has shape (..., 4, (max_degree+1)**2, features).\n",
    "    \n",
    "    x = e3nn.mean(x, axis=-3)  # 'x' now has shape (..., (max_degree+1)**2, features).\n",
    "        \n",
    "    # 3. Apply feature transformations.\n",
    "        \n",
    "    \"No pseudoscalar features yet\"\n",
    "    x = TensorDense(\n",
    "            features=self.features, max_degree=self.max_degree, irreps_out=None, use_gaunt=self.use_gaunt\n",
    "        )(x)\n",
    "    \n",
    "    \"Pseduoscalar features in tensor product\"\n",
    "    x = TensorDense(\n",
    "            features=self.features, max_degree=self.max_degree, irreps_out=\"0e + 0o\", use_gaunt=self.use_gaunt\n",
    "        )(x)\n",
    "\n",
    "    x = x.axis_to_mul()\n",
    "    # 4. Predict logits (with an ordinary Dense layer).\n",
    "    logits = torch.nn.Linear(features=tetracubes.shape[0])(x.array)  # Logits has shape (..., 2).\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import nn\n",
    "\n",
    "class OrdinaryModel:\n",
    "  features = 8\n",
    "  \n",
    "  def __init__(self):\n",
    "      self.layers: List[Callable[[Tensor], Tensor]] = [\n",
    "        nn.Linear(12, self.features), Tensor.relu, # 'x' has shape (..., features).\n",
    "        nn.Linear(self.features, self.features), Tensor.relu,\n",
    "        nn.Linear(self.features, tetracubes.shape[0])] \n",
    "        \n",
    "  def __call__(self, shapes):  # The 'shapes' array has shape (..., 4, 3).\n",
    "    # 1. Center shapes at origin (for translational invariance).\n",
    "    shapes = shapes - Tensor.mean(shapes, keepdim=True, axis=-2)  # 'shapes' still has shape (..., 4, 3).\n",
    "\n",
    "    # 2. Flatten xyz coordinates (input features).\n",
    "    x = Tensor.reshape(shapes, (*shapes.shape[:-2], -1))  # 'x' has shape (..., 4*3).\n",
    "\n",
    "    return x.sequential(self.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, num_classes:int) -> Tensor:\n",
    "    return (x[..., None] == Tensor.arange(num_classes, requires_grad=False, device=x.device)).where(1, 0)\n",
    "\n",
    "def cross_entropy_loss(logits, labels, label_smoothing:float=0.0):\n",
    "    return logits.sparse_categorical_crossentropy(labels).mean()\n",
    "\n",
    "def compute_accuracy(logits, labels):\n",
    "    return Tensor.mean(Tensor.argmax(logits, -1) == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, batch):\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(batch[\"shapes\"])\n",
    "    print(logits.shape)\n",
    "    print(batch[\"labels\"].shape)\n",
    "    loss = cross_entropy_loss(logits, batch[\"labels\"])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    accuracy = compute_accuracy(logits, batch[\"labels\"])\n",
    "    return loss.realize(), accuracy.realize()\n",
    "\n",
    "\n",
    "def eval_step(model, batch):\n",
    "    logits = model(batch[\"shapes\"])\n",
    "    loss = cross_entropy_loss(logits, batch[\"labels\"])\n",
    "    accuracy = compute_accuracy(logits=logits, labels=batch[\"labels\"])\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model, train_data, valid_data, num_epochs, learning_rate, batch_size\n",
    "):\n",
    "    # Initialize model parameters and optimizer state.\n",
    "    \n",
    "    optimizer = nn.optim.Adam(nn.state.get_parameters(model), lr=learning_rate)\n",
    "\n",
    "    # Determine the number of training steps per epoch.\n",
    "    train_size = train_data[\"shapes\"].shape[0]\n",
    "    steps_per_epoch = train_size // batch_size\n",
    "\n",
    "    # Train for 'num_epochs' epochs.\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Draw random permutations for fetching batches from the train data.\n",
    "        perms = Tensor(np.random.permutation(train_size))\n",
    "        perms = perms[\n",
    "            : steps_per_epoch * batch_size\n",
    "        ]  # Skip the last batch (if incomplete).\n",
    "        perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "        # Loop over all batches.\n",
    "        train_loss = 0.0  # For keeping a running average of the loss.\n",
    "        train_accuracy = 0.0  # For keeping a running average of the accuracy.\n",
    "        for i, perm in enumerate(perms):\n",
    "            batch = {k: v[perm, ...] for k, v in train_data.items()}\n",
    "            if i == 0:\n",
    "                print(\"batch\", batch[\"shapes\"].shape)\n",
    "            loss, accuracy = train_step(\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                batch=batch,\n",
    "            )\n",
    "            train_loss += (loss - train_loss) / (i + 1)\n",
    "            train_accuracy += (accuracy - train_accuracy) / (i + 1)\n",
    "\n",
    "        # Evaluate on the test set after each training epoch.\n",
    "        valid_loss, valid_accuracy = eval_step(\n",
    "            model=model, batch=valid_data\n",
    "        )\n",
    "\n",
    "        # Print progress.\n",
    "        print(f\"epoch: {epoch}\")\n",
    "        print(\n",
    "            f\"  train: loss {train_loss : 4.2f}, accuracy {train_accuracy * 100 : 6.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"  valid: loss {valid_loss : 4.2f}, accuracy {valid_accuracy * 100 : 6.2f}%\"\n",
    "        )\n",
    "\n",
    "    # Return final model parameters.\n",
    "    return nn.state.get_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train and test datasets.\n",
    "train_data, valid_data = generate_datasets()\n",
    "\n",
    "# Define training hyperparameters.\n",
    "learning_rate = 0.005\n",
    "num_epochs = 5\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch (16, 4, 3)\n",
      "(16, 2)\n",
      "(16,)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "backward not implemented for <class 'tinygrad.mlops.Eq'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[191], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the ordinary model.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m ordinary_model \u001b[38;5;241m=\u001b[39m OrdinaryModel()\n\u001b[0;32m----> 4\u001b[0m ordinary_params \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordinary_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[189], line 47\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, valid_data, num_epochs, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 47\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (loss \u001b[38;5;241m-\u001b[39m train_loss) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     53\u001b[0m train_accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (accuracy \u001b[38;5;241m-\u001b[39m train_accuracy) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[189], line 7\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, optimizer, batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m cross_entropy_loss(logits, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      9\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m compute_accuracy(logits, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/GitHub/e3nn-pt2/.venv/lib/python3.10/site-packages/tinygrad/tensor.py:282\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t0 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepwalk()):\n\u001b[1;32m    281\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (t0\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 282\u001b[0m   grads \u001b[38;5;241m=\u001b[39m \u001b[43mt0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazydata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m   grads \u001b[38;5;241m=\u001b[39m [Tensor(g, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m ([grads] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(t0\u001b[38;5;241m.\u001b[39m_ctx\u001b[38;5;241m.\u001b[39mparents) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m grads)]\n\u001b[1;32m    285\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m t, g \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(t0\u001b[38;5;241m.\u001b[39m_ctx\u001b[38;5;241m.\u001b[39mparents, grads):\n",
      "File \u001b[0;32m~/Documents/GitHub/e3nn-pt2/.venv/lib/python3.10/site-packages/tinygrad/tensor.py:28\u001b[0m, in \u001b[0;36mFunction.backward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparents \u001b[38;5;241m=\u001b[39m tensors\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward not implemented for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward not implemented for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(fxn:Type[Function], \u001b[38;5;241m*\u001b[39mx:Tensor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     32\u001b[0m   ctx \u001b[38;5;241m=\u001b[39m fxn(x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;241m*\u001b[39mx)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: backward not implemented for <class 'tinygrad.mlops.Eq'>"
     ]
    }
   ],
   "source": [
    "# Train the ordinary model.\n",
    "ordinary_model = OrdinaryModel()\n",
    "\n",
    "ordinary_params = train_model(\n",
    "    model=ordinary_model,\n",
    "    train_data=train_data,\n",
    "    valid_data=valid_data,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from https://e3x.readthedocs.io/stable/_modules/e3x/so3/rotations.html#random_rotation\n",
    "\n",
    "def random_rotation(\n",
    "    perturbation: float = 1.0,\n",
    "    num: int = 1,  # When num=1, leading dimension is automatically squeezed.\n",
    "):\n",
    "  r\"\"\"Samples a random :math:`3\\times3` rotation matrix.\n",
    "\n",
    "  Samples random :math:`3\\times3` rotation matrices from :math:`\\mathrm{SO(3)}`.\n",
    "  The ``perturbation`` parameter controls how strongly random points on a sphere\n",
    "  centered on the origin are perturbed by the rotation. For\n",
    "  ``perturbation=1.0``, any point on the sphere is rotated to any other point on\n",
    "  the sphere with equal probability. If ``perturbation<1.0``, returned rotation\n",
    "  matrices are biased to identity matrices. For example, with\n",
    "  ``perturbation=0.5``, a point on the sphere is rotated to any other point on\n",
    "  the same hemisphere with equal probability.\n",
    "\n",
    "  Example:\n",
    "    >>> import jax\n",
    "    >>> import e3x\n",
    "    >>> e3x.so3.random_rotation(jax.random.PRNGKey(0), perturbation=1.0)\n",
    "    Array([[-0.93064284, -0.11807037,  0.34635717],\n",
    "           [ 0.33270139,  0.1210826 ,  0.9352266 ],\n",
    "           [-0.15236041,  0.9855955 , -0.07340252]], dtype=float32)\n",
    "    >>> e3x.so3.random_rotation(jax.random.PRNGKey(0), perturbation=0.0)\n",
    "    Array([[1., 0., 0.],\n",
    "           [0., 1., 0.],\n",
    "           [0., 0., 1.]], dtype=float32)\n",
    "\n",
    "  Args:\n",
    "    key: A PRNG key used as the random key.\n",
    "    perturbation: A value between 0.0 and 1.0 that determines the perturbation.\n",
    "    num: Number of returned rotation matrices.\n",
    "\n",
    "  Returns:\n",
    "    An Array of shape :math:`(\\mathrm{num}, 3, 3)` or :math:`(3, 3)` (if num =\n",
    "    1) representing random :math:`3\\times3` rotation matrices.\n",
    "  \"\"\"\n",
    "  # Check that perturbation is a meaningful value.\n",
    "  if not 0.0 <= perturbation <= 1.0:\n",
    "    raise ValueError(\n",
    "        f'perturbation must be between 0.0 and 1.0, received {perturbation}'\n",
    "    )\n",
    "  # Draw random numbers and transform them.\n",
    "  twopi = 2 * np.pi\n",
    "  u = torch.randn((num, 3))\n",
    "  sqrt1 = torch.sqrt(1 - u[..., 0])\n",
    "  sqrt2 = torch.sqrt(u[..., 0])\n",
    "  angl1 = twopi * u[..., 1]\n",
    "  angl2 = twopi * u[..., 2]\n",
    "  # Construct random quaternion.\n",
    "  r = sqrt1 * torch.sin(angl1)\n",
    "  i = sqrt1 * torch.cos(angl1)\n",
    "  j = sqrt2 * torch.sin(angl2)\n",
    "  k = sqrt2 * torch.cos(angl2)\n",
    "  # Perturbation (Slerp starting from identity quaternion).\n",
    "  flip = r < 0  # Flip sign if r < 0 (always take the shorter route).\n",
    "  r = torch.where(flip, -r, r)\n",
    "  i = torch.where(flip, -i, i)\n",
    "  j = torch.where(flip, -j, j)\n",
    "  k = torch.where(flip, -k, k)\n",
    "  phi = torch.arccos(r)\n",
    "  sinphi = torch.sin(phi)\n",
    "  # Prevent division by zero.\n",
    "  zeromask = torch.abs(sinphi) < 1e-9\n",
    "  f1 = torch.where(\n",
    "      zeromask, 1 - perturbation, np.sin((1 - perturbation) * phi) / sinphi\n",
    "  )\n",
    "  f2 = torch.where(zeromask, perturbation, np.sin(perturbation * phi) / sinphi)\n",
    "  r, i, j, k = f1 + f2 * r, f2 * i, f2 * j, f2 * k\n",
    "  # Construct rotation matrix.\n",
    "  i2, j2, k2 = i * i, j * j, k * k\n",
    "  ij, ik, jk, ir, jr, kr = i * j, i * k, j * k, i * r, j * r, k * r\n",
    "  row1 = torch.stack((1 - 2 * (j2 + k2), 2 * (ij - kr), 2 * (ik + jr)), axis=-1)\n",
    "  row2 = torch.stack((2 * (ij + kr), 1 - 2 * (i2 + k2), 2 * (jk - ir)), axis=-1)\n",
    "  row3 = torch.stack((2 * (ik - jr), 2 * (jk + ir), 1 - 2 * (i2 + j2)), axis=-1)\n",
    "  rot = torch.squeeze(torch.stack((row1, row2, row3), axis=-1))\n",
    "  return rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Tensor' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m ordinary_accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(perturbations))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, perturbation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(perturbations):\n\u001b[0;32m----> 8\u001b[0m   rot \u001b[38;5;241m=\u001b[39m random_rotation(perturbation\u001b[38;5;241m=\u001b[39mperturbation, num\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshapes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m   rotated_shapes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28;01mlambda\u001b[39;00m x, r: x\u001b[38;5;129m@r\u001b[39m)(valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshapes\u001b[39m\u001b[38;5;124m'\u001b[39m], rot)\n\u001b[1;32m     10\u001b[0m   rotated_valid_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshapes\u001b[39m\u001b[38;5;124m'\u001b[39m: rotated_shapes, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Tensor' has no len()"
     ]
    }
   ],
   "source": [
    "# Determine the accuracy of the equivariant and ordinary models for rotated shapes with different\n",
    "# perturbation magnitudes (a perturbation of 0.0 gives identity matrices, a perturbation of 1.0 gives\n",
    "# fully random rotation matrices).\n",
    "perturbations = np.linspace(0.0, 1.0, num=6)\n",
    "ordinary_accuracy = np.zeros(len(perturbations))\n",
    "\n",
    "for i, perturbation in enumerate(perturbations):\n",
    "  rot = random_rotation(perturbation=perturbation, num=len(valid_data['shapes']))\n",
    "  rotated_shapes = torch.vmap(lambda x, r: x@r)(valid_data['shapes'], rot)\n",
    "  rotated_valid_data = {'shapes': rotated_shapes, 'labels': valid_data['labels']}\n",
    "#   _, equivariant_accuracy[i] = eval_step(equivariant_model.apply, rotated_valid_data, equivariant_params)\n",
    "  _, ordinary_accuracy[i] = eval_step(ordinary_model, criterion, rotated_valid_data)\n",
    "#   _, e3nn_accuracy[i] = eval_step(e3nn_model.apply, rotated_valid_data, e3nn_params)\n",
    "#   _, gtp_accuracy[i] = eval_step(gtp_model.apply, rotated_valid_data, gtp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results.\n",
    "plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "plt.xlabel('rotational perturbation [a.u.]')\n",
    "plt.ylabel('accuracy [%]')\n",
    "plt.plot(perturbations, ordinary_accuracy * 100, label='simple mlp model')\n",
    "plt.hlines(y=100/tetracubes.shape[0], xmin=0.0, xmax=1.0, color='k', ls=':', label='random')\n",
    "plt.legend(loc='center right')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
