{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# from torch_cluster import radius_graph\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data, DataLoader\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_scatter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scatter\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me3nn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m o3\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch_cluster import radius_graph\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_scatter import scatter\n",
    "\n",
    "from e3nn import o3\n",
    "from e3nn.nn import FullyConnectedNet, Gate\n",
    "from e3nn.o3 import FullyConnectedTensorProduct\n",
    "from e3nn.math import soft_one_hot_linspace\n",
    "from e3nn.util.test import assert_equivariant\n",
    "\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Disable future warnings.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for left and right screws.\n",
    "tetracubes = torch.tensor([\n",
    "  # Right screw.\n",
    "  [ [ -0.50,  0.25, -0.25 ], [ -0.50,  0.25,  0.75 ],\n",
    "    [  0.50,  0.25, -0.25 ], [  0.50, -0.75, -0.25 ] ],\n",
    "  # Left screw.\n",
    "  [ [ -0.75,  0.50, -0.25 ], [  0.25, -0.50,  0.75 ],\n",
    "    [  0.25,  0.50, -0.25 ], [  0.25, -0.50, -0.25 ] ],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets(num_train=1000, num_valid=100, noise_scale=0.05):\n",
    "\n",
    "  # Assign a label to each tetracube.\n",
    "  labels = torch.arange(tetracubes.shape[0])\n",
    "\n",
    "  # Randomly choose among the 2 tetracubes to generate train and validation datasets.\n",
    "  train_choice = torch.multinomial(torch.ones(tetracubes.shape[0]), num_samples=num_train, replacement=True)\n",
    "  valid_choice = torch.multinomial(torch.ones(tetracubes.shape[0]), num_samples=num_valid, replacement=True)\n",
    "  train_shapes = tetracubes[train_choice]\n",
    "  valid_shapes = tetracubes[valid_choice]\n",
    " \n",
    "  train_labels = labels[train_choice]\n",
    "  valid_labels = labels[valid_choice]\n",
    "\n",
    "  # Add Gaussian noise for some variety.\n",
    "  train_shapes += noise_scale * torch.randn(train_shapes.shape)\n",
    "  valid_shapes += noise_scale * torch.randn(valid_shapes.shape)\n",
    "\n",
    "  # Return final train and validation datasets.\n",
    "  train_data = dict(shapes=train_shapes, labels=train_labels)\n",
    "  valid_data = dict(shapes=valid_shapes, labels=valid_labels)\n",
    "  return train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Protocol, Tuple, Union\n",
    "import jaxtyping\n",
    "\n",
    "Array = torch.Tensor\n",
    "Float = jaxtyping.Float\n",
    "\n",
    "def basis(\n",
    "    r: torch.Tensor,\n",
    "    max_degree: int,\n",
    "    num: int,\n",
    "    # radial_fn: Callable[[Float[Array, '...'], int], Float[Array, '... num']],\n",
    "):\n",
    "    r\"\"\"Basis function corresponding to e3x.nn.basis which uses\n",
    "        e3nn.spherical_harmonics for angular functions\n",
    "    \"\"\"\n",
    "    \n",
    "    original_shape = r.shape[:-1]\n",
    "    r = r.reshape(-1, 3)\n",
    "\n",
    "    # Normalize input vectors.\n",
    "    a = torch.maximum(torch.max(torch.abs(r)), torch.finfo(r.dtype).tiny)\n",
    "    b = r / a\n",
    "    norm = a * torch.sqrt(torch.sum(b * b, dim=-1, keepdim=True))\n",
    "    u = r / torch.where(norm > 0, norm, 1)\n",
    "    norm = norm.squeeze(-1)  # (...)\n",
    "\n",
    "    # radial function\n",
    "    # rbf = radial_fn(norm, num)  # (..., N)\n",
    "\n",
    "    # basis function\n",
    "    ylm = e3nn.spherical_harmonics(e3nn.s2_irreps(max_degree), u, normalize=\"component\")\n",
    "    return ylm\n",
    "    \n",
    "    product = lambda x, weight: lambda w: w * x(weight)(ylm, rbf)\n",
    "\n",
    "    return product.reshape((*original_shape, *product.shape[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDense(torch.nn.Module):\n",
    "\n",
    "    features: int\n",
    "    max_degree: int\n",
    "    irreps_out: e3nn.Irreps\n",
    "    use_gaunt: bool\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: e3nn.IrrepsArray) -> e3nn.IrrepsArray:\n",
    "\n",
    "        x1 = e3nn.o3.Linear(irreps_in=x.irreps, irreps_out=x.irreps, channel_out=self.features)(x)\n",
    "        x2 = e3nn.o3.Linear(irreps_in=x.irreps, irreps_out=x.irreps, channel_out=self.features)(x)\n",
    "            \n",
    "        # Keep irreps only up to max_degree.\n",
    "        filter_ir_out = e3nn.tensor_product(x1.irreps, x2.irreps).filter(\n",
    "            lmax=self.max_degree\n",
    "        )\n",
    "    \n",
    "        tp = \n",
    "\n",
    "        # Additionally, filter out irreps.\n",
    "        irreps_out = self.irreps_out\n",
    "        if irreps_out is None:\n",
    "            irreps_out = tp.irreps\n",
    "\n",
    "        x = e3nn.o3.Linear(irreps_in=tp.irreps_out, irreps_out=irreps_out)(tp)        \n",
    "        return x\n",
    "\n",
    "class E3NNModel(torch.nn.Module):\n",
    "  features = 8\n",
    "  max_degree = 3\n",
    "  use_gaunt: bool = False\n",
    "\n",
    "  def __call__(self, shapes):  # The 'shapes' array has shape (..., 4, 3).\n",
    "      \n",
    "    # 1. Center shapes at origin (for translational invariance).\n",
    "    shapes -= torch.mean(shapes, keepdims=True, axis=-2)   # 'shapes' still has shape (..., 4, 3).\n",
    "    \n",
    "    # 2. Featurize by expanding cube midpoints in basis functions and taking the mean over the 4 cubes.\n",
    "    \n",
    "    x = basis( \n",
    "      shapes,\n",
    "      num=self.features,\n",
    "      max_degree=self.max_degree,\n",
    "    #   radial_fn=functools.partial(e3x.nn.triangular_window, limit=2.0),\n",
    "    ) # 'x' has shape (..., 4, (max_degree+1)**2, features).\n",
    "    \n",
    "    x = e3nn.mean(x, axis=-3)  # 'x' now has shape (..., (max_degree+1)**2, features).\n",
    "        \n",
    "    # 3. Apply feature transformations.\n",
    "        \n",
    "    \"No pseudoscalar features yet\"\n",
    "    x = TensorDense(\n",
    "            features=self.features, max_degree=self.max_degree, irreps_out=None, use_gaunt=self.use_gaunt\n",
    "        )(x)\n",
    "    \n",
    "    \"Pseduoscalar features in tensor product\"\n",
    "    x = TensorDense(\n",
    "            features=self.features, max_degree=self.max_degree, irreps_out=\"0e + 0o\", use_gaunt=self.use_gaunt\n",
    "        )(x)\n",
    "\n",
    "    x = x.axis_to_mul()\n",
    "    # 4. Predict logits (with an ordinary Dense layer).\n",
    "    logits = torch.nn.Linear(features=tetracubes.shape[0])(x.array)  # Logits has shape (..., 2).\n",
    "\n",
    "    return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
